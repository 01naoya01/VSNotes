---
tags:
    - AntBook
---

グラフの例はこの図

http://www.deqnotes.net/acmicpc/dijkstra/

頂点数，辺数，辺が出てる頂点,辺が入る頂点,辺のコスト  の順に入力していく場合のテストケース

6 9 0 1 5 0 3 4 0 4 2 1 2 6 1 3 2 2 5 4 3 4 3 3 5 2 4 5 6

6 9 0 1 0 3 0 4 1 2 1 3 2 5 3 4 3 5 4 5

# 隣接行列と隣接リストについて

隣接行列は2次元配列で実現可能

隣接リストはソースコードに示した方法で実現可能

蟻本にもある通り，隣接行列は確保するメモリ量が多いが，隣接リストはその心配はない．

ただ，隣接行列なら2次元配列で実現できているので，例えばiからjに辺があるかどうかの確認はg[i][j]の中身を参照するだけでいいので，計算量は必要ない

しかし，隣接リストの場合は，iのリストを走査しなければならない，つまり最悪時間でO(n)かかる (この計算時間量はiのリストに全ての頂点が入っていた場合，要するにiから全ての頂点に辺を持っていた場合)

# 隣接リストの実現方法について
実現方法2は頂点に属性を与える場合のみに使う．

頂点に属性を与えたいわけではないなら，どのような場合でも実現方法1を使うべきであると思う．

実現方法2に関しては構造体の中に構造体を要素として配列を入れて，辺を実現する．そのような構造体を要素とする配列が隣接リストになる．

つまりその隣接リストの頂点を構造体として定義しているのでその構造体に頂点の属性を入れることができる．

# 2-5の隣接リストの実現方法2の構造体について

G[]の各要素が構造体vertexになってる
↓
ってことは各要素にedge[]とcostを持ってる
↓
そのedge[]の各要素は構造体vertexのポインタになってる

だからedge[]には他のvertexのポインタを格納する

G[s].edge.push_back(&G[t]);

↑つまりこれはG[s]のedge[] の最後尾にG[t]のポインタを入れている.それができるのは，edge[]の各要素がvertex型のポインタを格納するように定義しているからである 

# DFSを使って連結判定や閉路判定について

連結判定は，二部グラフ判定の時のように，色なしを0で色付きを1として，とある頂点からdfsで塗っていって，dfsが終わったら塗ってない色がないかを確認する．もし塗ってない色があれば，それはdfsで塗れなかった色で，その頂点は別の連結成分である．

閉路の場合は，辺にチェックをつけていって，dfs中にチェック済みの辺があれば閉路があったといえる．

# ベルマンフォードとダイクストラにおいての負閉路について

負閉路があれば，ベルマンフォードでもダイクストラでも正しい最短路を求めることはできない

ただ，負閉路があればベルマンフォードは負閉路があるよって検出できる(ダイクストラは検出できず，ただただ間違った値が出てくる)

なお，負閉路がなくても負の辺はあるって場合もあると思うが，ベルマンフォードは負の辺はあっても正しい結果を出力できるが，ダイクストラは負の辺があったら正しい値がでない

しかし，計算量はダイクストラの方が早いので，負の辺がないと分かっているならダイクストラを使った方がいい

# ベルマンフォードの計算量

蟻本の解説を読めば分かると思うが一応説明する．

whileの中のforはE回のループで，while自体のループ回数を考える．

whileはforで更新が一回もない場合の時に脱出できる．もし更新があればもう一回forを回して更新する．つまり更新できなくなるまでwhileを回すということである．

一回のforで更新する回数は一回とは限らず，複数回更新する可能性は勿論あるが，更新しなくなるってことはどの辺を調べても最短となっているので，つまり全ての点で最短になってるってことである．

理解を深めるために書くが，この解き方には無駄がある．更新はd[j])=d[i]+コスト(i,j)とするが，d[i]が最短じゃなければd[j]も最短じゃない．

ただ，全部の辺に毎回最短かをチェックして，更新がなくなるまでチェックするので，更新しなくなったってことはd[i]も最短で，勿論d[j]も最短ということになる．

つまり，毎回のforで，少なくとも1つの頂点には最短が求められる．

だからforを回す回数は高々|V|-1(始点を抜いた数)となる．

よって計算量はO(|V||E|)となる．

# ダイクストラ法のヒープを使わない場合の計算量とヒープを使った場合の計算量

隣接リストを使った場合の最短距離の更新に要する計算量というのは，for(int u=0;u< V;u++){d[u]=min(d[u],d[v]+cost[v][u]);}の部分である．

なぜなら，更新する頂点に繋がってる辺について調べればいいだけだから，隣接リストを使えばO(|E|)になる．

次にヒープを使った場合，つまり実際に使うダイクストラ法の計算量について説明する．

まず，蟻本の説明の真ん中の部分(高速化したいのいは値の挿入(変更)と~~~となり，全体の計算量はO(|E|log|V|)となります．)のところについては，これは要するにヒープを使った場合のダイクストラ法の計算量について説明されているだけで，内容が冗長的なのでこれはアルゴリズムのwordの資料を見た方が分かりやすい．

# ダイクストラ法のpriority_queueを使った場合の計算量

次にpriority_queueを使った場合の計算量について説明する．これはアルゴリズムのwordの資料を見て計算量を理解した上で以下の説明を見てくれたらかなり分かりやすい．

まず，whileの中のforはd(v)×log|V|なので，全体では|E|log|V|となる．ここで誤解のないように一応言うが，全体ではっていうのはwhileを考慮したforの計算量という意味である．

次にforの上のところに関しては，whileは|E|回のループ回数なので，上から|E|log|V|となる．

よって全体の計算量は|E|log|V|となる．

蟻本の説明に関して説明する．

vを最短の点として選んで，vに繋がってる頂点を全て確認して，条件式を満たせばヒープに入れている．つまり，同じ頂点だが，複数のデータがヒープに格納されている可能性がある．

例えば(5,3)，(2,3)，(10,3)の三つがヒープに入ってる可能性がある．この場合頂点番号3についてのデータが3つ入ってるが，この3つの中だと最短距離は2なので(5,3)と(10,3)はいらない．

ただd[] には最短距離がちゃんと入ってるので，d[3]を確認して，それより大きいものは確認しないようにしている(その確認しないようにしてる作業がcontinueしてる部分である)．

例えばヒープから最小値を取り出すところから確認すると，最小値を取り出すので(2,3)が取り出される可能性はあるが，(5,3)，(10,3)が取り出される可能性はない．

尚且つ，(2,3)が取り出された後なら(5,3)，(10,3)が取り出される可能性はあるが，d[3]には2が入っていて，continueされるので，(5,3)，(10,3)が採用されて頂点番号3を再度確認するようなことはないということである．

# ワーシャルフロイド法について
Wikiのアイデアのところを見た方が圧倒的に分かりやすい．

https://ja.wikipedia.org/wiki/%E3%83%AF%E3%83%BC%E3%82%B7%E3%83%A3%E3%83%AB%E2%80%93%E3%83%95%E3%83%AD%E3%82%A4%E3%83%89%E6%B3%95

これが分かれば蟻本の言ってる意味も分かると思う．

蟻本の「このDPは同じ配列を使いまわして」っていうのは要するにd[k]とd[k-1]の区別をせずに更新していくってことである．

ただ，そもそもはDPの考え方からきてるアルゴリズムであり，kを増やすことでDPとなってるので，ループの順番はk,i,jである．kが最初でないといけない．

ベルマンフォードと同じように，負の辺があっても実行でき，負閉路があれば検出できる．

d[i][i]=マイナスとなるような頂点iがあれば負閉路があることが分かる．

# 経路復元について

説明に関しては蟻本を読めば大体は分かると思う．経路復元の計算量はO(|V|)と考えてよい．
O(|E|)の理由はよく分からないが，O(|V|)となるプログラムを作っているので，それを使えば何の問題もない．

# 幅優先探索を用いた全ての辺のコストが等しい場合の単一始点最短経路問題について

名前通り，全ての辺のコストが等しい場合，もしくはコストがない場合に使える.

コストがないということは辺にコストが1あるような感じで考える．

これで考えれば0なら辺がなく，1なら辺があるって感じになる．

計算量はすなわちBFSの計算量なのでO(E+V)となる．

# 